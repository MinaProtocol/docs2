---
title: Migrating Devnet/Mainnet Archive to Berkeley Archive 
sidebar_label: Performing Archive migration
hide_title: true
description: Steps to properly migrate archives from Devnet/Mainnet to Berkeley.
keywords:
  - Berkeley
  - upgrade
  - archive migration
  - planning 
  - prerequisites
  - mina archive node
  - archive node
---

### Migration process

As mentioned in [Planning the Archive Migration](/berkeley-upgrade/understanding-archive-migration), the devent/mainnet migration can take up to a couple of days. 
Therefore, it is recommended to split migration into 3 stages:

- **Stage1:** Initial migration

- **Stage2:** Incremental migration

- **Stage3:** Remainder migration

Each stage has three migration phases:

- **Phase 1:** Copying data from devnet/mainnet database and precomputed blocks using the **berkeley_migration** app.

- **Phase 2:** Populating new berkeley tables using the **replayer app in migration mode**

- **Phase 3:** Additional validation for migrated database

At the end of entire cycle of migration you will recieve two databases:

- source database with original devnet/mainnet data
- migrated datbase with orginal devnet/mainnet data converted to berkeley schea

Review these phases and stages before you start the migration:

### Simplified approach

For user convenience we offer berkeley_migration.sh script. 
The script was created for users who either do not need to delve into the details of migration or whose environment does not require a special approach to migration

#### Stage 1: Initial migration

```
mina-berkeley-migration-script  \ 
   initial \
   --genesis-ledger ledger.json \
   --source-db postgres://postgres:postgres@localhost:5432/source \
   --target-db postgres://postgres:postgres@localhost:5432/migrated \
   --blocks-bucket mina_network_block_data \
   --blocks-batch-size 50 \
   --network NETWORK
```

where: 

`-g | --genesis-ledger`:  *path to genesis ledger file*

`-s | --source-db`: *connection string to database to be migrated*

`-t | --target-db`: *connection string to database which will hold migrated data*

`-b | --blocks-bucket`: *name of precomputed blocks bucket. NOTICE: there is an assumption that precomputed blocks are named with format: `{network}-{height}-{state_hash}.json`*

`-bs | --blocks-batch-size`: *number of precomputed blocks to be fetch at once from Gcloud. Bigger number like 1000 can help speed up migration process*

`-n | --network`: *network name (devnet/mainnet) when determining precomputed blocks. NOTICE: there is an assumption that precomputed blocks are named with format: `{network}-{height}-{state_hash}.json`*


This command should output migration-replayer-XXX.json which should be used in next run

#### Incremental migration

```
mina-berkeley-migration-script \
   incremental \
   --genesis-ledger ledger.json \
   --source-db postgres://postgres:postgres@localhost:5432/source \
   --target-db postgres://postgres:postgres@localhost:5432/migrated \
   --blocks-bucket mina_network_block_data \
   --blocks-batch-size 50 \
   --network NETWORK \
   --replayer-checkpoint migration-checkpoint.json
```

where:

`-r | --replayer-checkpoint`: *path to genesis ledger file*

`-g | --genesis-ledger`: *path to genesis ledger file*

`-s | --source-db`: *connection string to database to be migrated*

`-t | --target-db`: *connection string to database which will hold migrated data*

`-b | --blocks-bucket`: *name of precomputed blocks bucket. NOTICE: there is an assumption that precomputed blocks are named with format: `{network}-{height}-{state_hash}.json`*

`-bs | --blocks-batch-size`: *number of precomputed blocks to be fetch at once from Gcloud. Bigger number like 1000 can help speed up migration process*

`-n | --network`: *network name (devnet/mainnet)) when determining precomputed blocks. NOTICE: there is an assumption that precomputed blocks are named with format: `{network}-{height}-{state_hash}.json`*
  
:info:

migration-checkpoint.json - is a last replayer checkpoint from initial run

#### Stage 3: Remainder migration

```
mina-berkeley-migration-script \
   final \
   --genesis-ledger ledger.json \
   --source-db postgres://postgres:postgres@localhost:5432/source \
   --target-db postgres://postgres:postgres@localhost:5432/migrated \
   --blocks-bucket mina_network_block_data \
   --blocks-batch-size 50 \
   --network NETWORK \
   --replayer-checkpoint migration-checkpoint.json \
   -fc fork-dump.json \
   -f fork-state-hash 
```

where: 

`-r | --replayer-checkpoint`: *path to replayer checkpoint file*

`-g | --genesis-ledger`: *path to genesis ledger file*

`-f | --fork-state-hash`: *fork state hash*

`-s | --source-db`: *connection string to database to be migrated*

`-t | --target-db`: *connection string to database which will hold migrated data*

`-b | --blocks-bucket`: *name of precomputed blocks bucket. NOTICE: there is an assumption that precomputed blocks are named with format: `{network}-{height}-{state_hash}.json`*

`-bs | --blocks-batch-size`: *number of precomputed blocks to be fetch at once from Gcloud. Bigger number like 1000 can help speed up migration process*

`-n | --network`: *network name (devnet/mainnet) when determining precomputed blocks. NOTICE: there is an assumption that precomputed blocks are named with format: `{network}-{height}-{state_hash}.json`*

`-fc | --fork-config`: *fork genesis config file is the new genesis config. It would be distributed with the new daemon and would also be published after fork block is announced*
  
### Advanced approach

If simplified berkeley migraion script is for some reasons not suitable for you, there is always a possibility to run migration using berkeley_migration and replayer apps without
an interface which script provides. Please refer to below steps:

#### Stage 1: Initial migration

This stage is the very first one, which requires the initial `berkeley` schema only. It is a foundation for the next migration stage because it populates the migrated database and creates an initial checkpoint for further incremental migration.

- Inputs
   - Unmigrated devnet/mainnet database
   - Devnet/Mainnet genesis ledger 
   - Empty target `berkeley` database (empty means with schema created but without any content)

- Outputs
   - Migrated `devnet`/`mainnet` database to `berkeley` format from genesis up to the last canonical block in orginal database
   - Replayer checkpoint, which can be used for incremental migration

##### Phase 1: Berkeley migration app run

```
mina-berkeley-migration \
   --batch-size 1000 \
   --config-file genesis_ledgers/devnet.json \
   --mainnet-archive-uri {mainnet_connection_string} \
   --migrated-archive-uri {migrated_connection_string} \
   --blocks-bucket {bucket name} \
   --keep-precomputed-blocks \
   --stream-precomputed-blocks \
   --network NETWORK
```
where: 
`--network` - network name (devnet/mainnet) when determining precomputed blocks. There is an assumption that precomputed blocks are named with format: `{network}-{height}-{state_hash}.json`;
`genesis_ledgers/devnet.json` - is devnet genesis ledger. It is available in docker / debian or in [github sources](https://raw.githubusercontent.com/MinaProtocol/mina/e38c367994dba3d3293b48c7219486c32e9e3ca9/genesis_ledgers/devnet.json)

Note: When migrating devnet archive database, pass connection string of the devnet database to the flag `--mainnet-archive-uri`. 


##### Phase 2: Replayer in migration mode run

Replayer config must contain the Devnet/Mainnet ledger as the starting point. So first, you must prepare the replayer config file:

```
 jq '.ledger.accounts' genesis_ledger.json | jq  '{genesis_ledger: {accounts: .}}' > replayer_input_config.json
```

where:
   genesis_ledger.json is genesis file from which deamon bootstrap on particular network

Then:
```
 mina-migration-replayer \
   --migration-mode \
   --archive-uri {migrated_connection_string} \
   --input-file replayer_input_config.json \
   --checkpoint-interval 10000
```

where:
 - `archive-uri` - connection string to archive datbase 
 - `checkpoint-interval` - frequency of checkpoints file expressed in blocks count
 - `reference_replayer_input.json` is a file constructed out of network genesis ledger:
 
   ```
      jq '.ledger.accounts' genesis_ledger.json | jq  '{genesis_ledger: {accounts: .}}' > replayer_input_config.json
   ```

##### Phase 3: Validations

berkeley_migration_verifier app is capable of performing checks for both fully migrated and partially migrated database. 

```
 mina-berkeley-migration-verifier 
   pre-fork  \
   --mainnet-archive-uri {mainnet_connection_string} \
   --migrated-archive-uri {migrated_connection_string}  
```

where:
 - `mainnet-archive-uri` - connection string to original devnet/mainnet archive database 
 - `migrated-archive-uri` - connection string to migrated archive database

 Note: When migrating devnet archive database, pass connection string of the devnet database to the flag `--mainnet-archive-uri`. 
 
#### Stage 2: Incremental migration

After the initial migration, the data is migrated data up to the last canonical block. However, devnet/mainnet data is progressing with new blocks that must also be migrated again and again until the fork block is announced. 

:info: incremental migration can and probably must be repeated couple of times until fork block is announced by Mina Foundation.
You can run incremental migration several times with the latest devnet/mainnet database and the latest replayer checkpoint file.

- Inputs
   - Latest devnet/mainnet database
   - Devnet/Mainnet genesis ledger
   - Replayer checkpoint from last run 
   - Migrated berkeley database from initial migration 

- Outputs
   - Migrated devnet/mainnet database to berkeley up to last canonical block
   - Replayer checkpoint which can be used for next incremental migration

##### Phase 1: Berkeley migration app run

```
mina-berkeley-migration \
   --batch-size 1000 \
   --config-file FILE \
   --mainnet-archive-uri {mainnet_connection_string} \
   --migrated-archive-uri {migrated_connection_string} \
   --blocks-bucket {bucket name} \
   --keep-precomputed-blocks \
   --stream-precomputed-blocks \
   --network "mainnet"
```
where: 
`--network` - network name when determining precomputed blocks. There is an assumption that precomputed blocks are named with format: `{network}-{height}-{state_hash}.json`;
`--config-file` - Use genesis_ledgers/devnet.json for devnet migration and genesis_ledgers/mainnet.json for mainnet migration 

Note: When migrating devnet archive database, pass connection string of the devnet database to the flag `--mainnet-archive-uri`.

##### Phase 2: Replayer in migration mode run

```
 mina-replayer \
   --migration-mode \
   --archive-uri {migrated_connection_string} \
   --input-file replayer-checkpoint-XXXXX.json \
   --checkpoint-interval 10000
```

where `replayer-checkpoint-XXXXX.json` - is last checkpoint generated from previous migration

Incremental migration can be run continuously on top of initial migration or last incremental until fork block is announced 

##### Phase 3: Validations

berkeley_migration_verifier app is capable of performing checks for both fully migrated and partially migrated database. 

```
 mina-berkeley-migration-verifier 
   pre-fork  \
   --mainnet-archive-uri {mainnet_connection_string} \
   --migrated-archive-uri {migrated_connection_string}  
```

where:
 - `mainnet-archive-uri` - connection string to original archive database 

Note: When migrating devnet archive database, pass connection string of the devnet database to the flag `--mainnet-archive-uri`.

Incremental migration can be run continuously on top of initial migration or last incremental until fork block is announced. 

#### Stage 3: Remainder migration

When the fork block is announced, you must tackle the remainder migration. This is the last migration run 
you need to perform. In this stage, we are closing migration cycle by last migration of remainder blocks between 
current last canonical block and fork block (which can be pending, so we don't need to wait 290 blocks until it would become canonical). 
Here you need to use `--fork-state-hash` as additional parameter to berkeley-migration app

- Inputs
   - Latest devnet/mainnet database
   - Devnet/Mainnet genesis ledger
   - Replayer checkpoint from last run 
   - Migrated berkeley database from last run
   - Fork block state hash

- Outputs
   - Migrated devnet/mainnet database to berkeley up to fork point
   - Replayer checkpoint which can be used for replayer run on berkeley database

**The migrated database resulting from this stage of final migration is the one required to initialize your archive nodes on the upgraded network.**

##### Phase 1: Berkeley migration app run

You might notice a decrease in `batch-size` for precomputed blocks as the tool might hit missing precomputed blocks problem if you fetch too many of them in a single batch while trying to migrate the newest blocks in the chain:

```
mina-berkeley-migration \
   --batch-size 2 \
   --config-file FILE \
   --mainnet-archive-uri {mainnet_connection_string} \
   --migrated-archive-uri {migrated_connection_string} \
   --blocks-bucket {bucket name} \
   --keep-precomputed-blocks \
   --stream-precomputed-blocks \
   --network NETWORK \
   --fork-state-hash {fork-state-hash}
```
where:
`--config-file` - Use genesis_ledgers/devnet.json for devnet migration and genesis_ledgers/mainnet.json for mainnet migration; 
`--network` - network name (devnet/mainnet) when determining precomputed blocks. There is an assumption that precomputed blocks are named with format: `{network}-{height}-{state_hash}.json`;
`--fork-state-hash` last migrated block which will be used as a fork point 

Note: When migrating devnet archive database, pass connection string of the devnet database to the flag `--mainnet-archive-uri`.


**Info** When running the **berkeley-migration** app with fork-state-hash, there is no requirement for the fork state block to be canonical.
The tool automatically converts all pending blocks in the subchain, including the fork block, to canonical blocks.

##### Phase 2: Replayer in migration mode run

```
mina-replayer \
   --migration-mode \
   --archive-uri {migrated_connection_string} \
   --input-file replayer-checkpoint-XXXXX.json \
   --checkpoint-interval 10000 
```

where:
`replayer-checkpoint-XXXXX.json` - is last checkpoint generated from previous migration

It is important to save checkpoint which was dumped from replayer run, as it will be use in next migrations

##### Phase 3: Validations

berkeley_migration_verifier app is capable of performing checks for both fully migrated and partially migrated database. 

```
 mina-berkeley-migration-verifier 
   post-fork  \
   --mainnet-archive-uri {mainnet_connection_string} \
   --migrated-archive-uri {migrated_connection_string}  
   --fork-config-file genesis_config_fork.json
   --migrated-replayer-output replayer-checkpoint-XXXX.json
```

where:

`--fork-config-file` - Path to fork config file (alias: -fork-config-file)
`--mainnet-archive-uri` - Connection string to the devnet/mainnet archive database
`--migrated-archive-uri` - Connection string to the migrated archive database
`--migrated-replayer-output` - Path to migrated replayer output


### Example steps using Mina Foundation data for devnet

1. Download and import archive dump:

   ```sh
   wget -c https://storage.googleapis.com/mina-archive-dumps/devnet-archive-dump-2024-03-27_0000.sql.tar.gz

   tar -xf devnet-archive-dump-2024-03-27_0000.sql.tar.gz 

   psql -U postgres -a -f devnet-archive-dump-2024-03-27_0000.sql
   ```

2. Download migration software:

   ```sh
   CODENAME=bullseye
   CHANNEL=unstable
   VERSION=2.0.0berkeley-rc1-berkeley-c308efc-bullseye

   echo "deb [trusted=yes] http://packages.o1test.net $CODENAME $CHANNEL" | tee /etc/apt/sources.list.d/mina.list
   apt-get update
   apt-get install --allow-downgrades -y "mina-archive-berkeley-archive-migration=$VERSION"
   ```

3. Create empty database with schema only:

   ```sh
   wget https://raw.githubusercontent.com/MinaProtocol/mina/berkeley/src/app/archive/zkapp_tables.sql

   wget https://raw.githubusercontent.com/MinaProtocol/mina/berkeley/src/app/archive/create_schema.sql

   psql  -U postgres -c "CREATE DATABASE berkeley_migrated;"

   psql -U postgres -d berkeley_migrated -a -f create_schema.sql
   ```

4. Download devnet genesis ledger 


5. Stage 1: Initial migration

   5.a) Phase 1:

   ```sh
   mina-berkeley-migration \
      --batch-size 2000 \
      --config-file /etc/mina/genesis_ledgers/devnet.json \
      --mainnet-archive-uri postgres://postgres:postgres@localhost/archive_balances_migrated \
      --migrated-archive-uri postgres://postgres:postgres@localhost/berkeley_migrated \
      --blocks-bucket mina_network_block_data \
      --keep-precomputed-blocks \
      --stream-precomputed-blocks \
      --network devnet
   ```

   5.b) Phase 2:

   ```sh

   # devnet.json is genesis file from which deamon bootstrap on devnet
   jq '.ledger.accounts' devnet.json | jq  '{genesis_ledger: {accounts: .}}' > replayer_input_config.json

   mina-migration-replayer \
      --migration-mode \
      --archive-uri postgres://postgres:postgres@localhost:5432/berkeley_migrated \
      --input-file replayer_config_input.json \
      --checkpoint-interval 100 \
      --checkpoint-file-prefix migration
   ```

   5.c) Phase 3:

   ```sh
   mina-berkeley-migration-verifier 
      pre-fork  \
      --mainnet-archive-uri postgres://postgres:postgres@localhost/archive_balances_migrated \
      --migrated-archive-uri postgres://postgres:postgres@localhost:5432/berkeley_migrated 
   ```

6. Stage 2: Initial migration

   6.a) Phase 1:

   ```sh
   mina-berkeley-migration \
      --batch-size 2000 \
      --config-file /etc/mina/genesis_ledgers/devnet.json \
      --mainnet-archive-uri postgres://postgres:postgres@localhost/archive_balances_migrated \
      --migrated-archive-uri postgres://postgres:postgres@localhost/berkeley_migrated \
      --blocks-bucket mina_network_block_data \
      --network devnet
   ```

   6.b) Phase 2:

   ```sh
   mina-migration-replayer \
      --migration-mode \
      --archive-uri postgres://postgres:postgres@localhost:5432/berkeley_migrated \
      --input-file checkpoint-XXXX.json \
      --checkpoint-interval 100 \
      --checkpoint-file-prefix migration
   ```

   6.c) Phase 3:

   ```sh
   mina-berkeley-migration-verifier 
      pre-fork  \
      --mainnet-archive-uri postgres://postgres:postgres@localhost/archive_balances_migrated \
      --migrated-archive-uri postgres://postgres:postgres@localhost:5432/berkeley_migrated 
   ```

7. Stage 3: Remainder migration

   7.a) Phase 1:

   ```sh
   mina-berkeley-migration \
      --batch-size 2000 
      --config-file /etc/mina/genesis_ledgers/devnet.json \
      --mainnet-archive-uri postgres://postgres:postgres@localhost/archive_balances_migrated \
      --migrated-archive-uri postgres://postgres:postgres@localhost/berkeley_migrated \
      --blocks-bucket mina_network_block_data \
      --network devnet \
      --fork-state-hash "3NLdCBNrDseiDKvVj8rZ15k2oAUvx4XuCc8mzf6fL2CmqTJVVceM" 
   ```

   :warning: 3NLdCBNrDseiDKvVj8rZ15k2oAUvx4XuCc8mzf6fL2CmqTJVVceM - is an example random hash, please **do not user this hash** on the actual migration. Use the official hash as provided by Mina Foundation for the fork point.

   7.b) Phase 2:

   ```sh
   mina-replayer \
      --migration-mode \
      --archive-uri postgres://postgres:postgres@localhost:5432/berkeley_migrated \
      --input-file checkpoint-XXXX.json \
      --checkpoint-interval 100 \
      --checkpoint-file-prefix migration
   ```

   7.c) Phase 3:

   ```sh
   mina-berkeley-migration-verifier 
      pre-fork  \
      --mainnet-archive-uri postgres://postgres:postgres@localhost/archive_balances_migrated \
      --migrated-archive-uri postgres://postgres:postgres@localhost:5432/berkeley_migrated \
      --fork-config-file genesis_config_fork.json \
      --migrated-replayer-output migrated-checkpoint-XXX.json
   ```

## How to verify a successful migration

O1Labs and the Mina Foundation make every effort to provide reliable tools of high quality. However, it is not possible to eliminate all errors and test all possible Mainnet archives variations. 
All imporant checks are implemented in `mina-berkeley-migration-verifier` application.
However, if you want to perform them manually please follow below checklist:

1. #### All transaction (user command and internal command) hashes are left intact

Verify that the `user_command` and `internal_command` tables have the Devnet/Mainnet format of hashes. For example, `CkpZirFuoLVV...`.

2. #### Parent-child block relationship is preserved

Verify that a given block in the migrated archive has the same parent in the Devnet/Mainnet archive (`state_hash` and `parent_hash` columns) that was used as input.

3. #### Account balances remain the same

Verify the same balance exists for a given block in Mainnet and migrated databases.

## Tips and tricks

We are aware that the migration process can be very long (a couple of days). Therefore, we encourage using cron jobs that migrate data incrementally. 
The cron job requires access to Google Cloud buckets (or other storage):

- A bucket to store migrated-so-far database dumps
- A bucket to store checkpoint files


:info: We are tightly coupled with Gcloud infrastructure at this moment due to precomputed block upload mechanism.
This is the reason why we are using also buckets for storing dumpa and checkpoint. However, it is not required to use Gcloud for other things than 
precomputed blocks.  Any gsutil compatible storage backend (eg S3) can be used instead, with configuration.

Before running the cron job, upload an initial database dump and an initial checkpoint file. 

To create the files, run these steps locally:

1. Download a Devnet/Mainnet archive dump and load it into PostgreSQL.
2. Create a new, empty database using the new archive schema.
3. Run the berkeley-migration app against the Devnet/Mainnet and new databases.
4. Run the replayer app in migration mode with the --checkpoint-interval set to some suitable value (perhaps 100) and start with the original Devnet/Mainnet ledger in the input file.
5. Use pg_dump to dump the migrated database and upload it.
6. Upload the most recent checkpoint file.

The cron job performs the same steps in an automated fashion:

1. Pulls the latest Devnet/Mainnet archive dump and loads it into PostgresQL.
2. Pulls the latest migrated database and loads it into PostgreSQL.
3. Pulls the latest checkpoint file.
4. Runs the berkeley-migration app against the two databases.
5. Runs the replayer app in migration mode using the downloaded checkpoint file; the checkpoint interval should be smaller (perhaps 50) because there are typically only 200 or so blocks in a day.
7. Uploads the migrated database.
8. Uploads the most recent checkpoint file.

Be sure to monitor the cron job in case there are errors.

Just before the Berkeley upgrade, migrate the last few blocks by running locally:

1. Download the Devnet/Mainnet archive data directly from the k8s PostgreSQL node, not from the archive dump, and load it into PostgreSQL.
2. Download the most recent migrated database and load it into PostgresQL.
3. Download the most recent checkpoint file.
4. Run the berkeley-migration app against the two databases.
5. Run the replayer app in migration mode using the most recent checkpoint file.

It is worthwhile to perform these last steps as a dry run to make sure all goes well. You can run these steps as many times as needed.

### Known migration problems

#### Berkeley migration app is consuming all of my resources

When running a full migration, you can stumble on memory leaks that prevent you from cleanly performing the migration in one pass. A machine with 64 GB of RAM can be frozen after ~40k migrated blocks. Each 200 blocks inserted into the database increases the memory leak by 4–10 MB.

A potential workaround is to split migration into smaller parts using cron jobs or automation scripts.

Related Github issues:
- [#13714](https://github.com/MinaProtocol/mina/issues/13714)
- [#14924](https://github.com/MinaProtocol/mina/issues/14924)

## FAQ

#### Migrated database is missing orphaned blocks

By design, Berkeley migration omits orphaned blocks and, by default, migrates only canonical ( and pending if setup correctly ) blocks.

#### Replayer in migration mode overrides my old checkpoints

Replayer by default dumps the checkpoint to the current folder. All checkpoint files have a similar format:

`replayer-checkpoint-{number}.json.`

To modify the output folder and prefix, you can use the `--checkpoint-output-folder` and `--checkpoint-file-prefix` parameters to prevent override of old checkpoints.

#### Replayer in migration mode exits the process in the middle of the run

Most likely, there are some missing blocks in the Devnet/Mainnet database. Ensure that you patched the Devnet/Mainnet archive before the migration process.

#### How to migrate Devnet/Mainnet pending blocks

In the first phase of migration use the `--end-global-slot` parameter. 

In the second phase of migration, add property `target_epoch_ledgers_state_hash` with the expected `state_hash` value:

```json
{
   "target_epoch_ledgers_state_hash":"{target_state_hash}",
   "genesis_ledger": "..."
}
```

#### I am receiving errors from gsutil regarding missing precomputed blocks

When migrating last chunk of blocks from devnet/mainnet, there can be an issue for runs with
large `batch-size` argument inputs. As an optimization gsutil is trying to fetch as `block-size` amount of precomputed blocks.
However, when precomputed blocks bucket has not contain enough (= `block-size` amount) precomputed blocks gsutil may panic stopping migration process.
Our recommendation is to restart process with smaller number of `batch-size`. If you are running migration just after fork block is announced it is best
to have `--block-size` argument set up to 5.
